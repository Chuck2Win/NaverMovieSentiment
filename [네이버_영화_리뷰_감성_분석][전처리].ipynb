{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[네이버 영화 리뷰 감성 분석][전처리]",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOtSuegzIGGYr0k2eQpR7Tu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chuck2Win/NaverMovieSentiment/blob/master/%5B%EB%84%A4%EC%9D%B4%EB%B2%84_%EC%98%81%ED%99%94_%EB%A6%AC%EB%B7%B0_%EA%B0%90%EC%84%B1_%EB%B6%84%EC%84%9D%5D%5B%EC%A0%84%EC%B2%98%EB%A6%AC%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BszE_y5aV38K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "becc5988-96fa-442d-a141-86c22a43901e"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sentencepiece as spm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMu2wTjjlSLY",
        "colab_type": "text"
      },
      "source": [
        "# 네이버 감성 분석 데이터 전처리\n",
        "1. 한글이 아닌 부분 정제  \n",
        "2. train, val, test set으로 나누기  \n",
        "3. sentencepiece로 tokenizer 구축하기 ( vocab size 32000 ) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3RzQokiXkxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "004b68f1-383a-4d22-a578-076db0cec3f1"
      },
      "source": [
        "# 네이버 감성 분석 데이터 불러오기\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"./ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"./ratings_test.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./ratings_test.txt', <http.client.HTTPMessage at 0x7f9849ceb278>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL9Z1G2BXr8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_table('./ratings_train.txt')\n",
        "test_data = pd.read_table('./ratings_test.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GxRwFstudbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train, validation dataset 만들기\n",
        "train_data,val_data=train_test_split(train_data,test_size=30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oSDlBUZvCXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f208dc3b-4e12-4079-cbba-46a10656dc3e"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120000\n",
            "30000\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuV7e17fBJfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 한글이 아닌 부분은 과감히 제거\n",
        "def cleanse(sentence):\n",
        "    result=sentence.lower()\n",
        "    result=re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힇 ]','',result)\n",
        "    return result\n",
        "\n",
        "# 결측치가 있긴 하지만, 실제 test에서도 혹은 추후 데이터에서 결측치가 있을수도 있다고 생각해서 일단 학습\n",
        "train_data['document']=train_data['document'].astype(str)\n",
        "val_data['document']=val_data['document'].astype(str)\n",
        "test_data['document']=test_data['document'].astype(str)\n",
        "\n",
        "# 정제 작업\n",
        "train_data['document']=train_data['document'].apply(lambda i : cleanse(i))\n",
        "val_data['document']=val_data['document'].apply(lambda i : cleanse(i))\n",
        "test_data['document']=test_data['document'].apply(lambda i : cleanse(i))\n",
        "\n",
        "# 그리고 csv로 저장\n",
        "train_data[['document','label']].to_csv('./Train_data.csv',index=False)\n",
        "val_data[['document','label']].to_csv('./Val_data.csv',index=False)\n",
        "test_data[['document','label']].to_csv('./Test_data.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knqsvYop4K54",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db10a4b9-a583-4b60-81cf-d7de4829dde2"
      },
      "source": [
        "# sentence piece\n",
        "# sentence piece 구축\n",
        "with open('naver_review.txt', 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(train_data['document'].astype(str)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qltW044k5CxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spm.SentencePieceTrainer.Train('--input=naver_review.txt --model_prefix=naver_32000 --vocab_size=32000 --model_type=bpe --max_sentence_length=9999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS]')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}